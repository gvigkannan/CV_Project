{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time \n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt \n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'i:\\\\WPI\\\\Fall 2020\\\\Computer Vision - RBE 549\\\\CV Project\\\\Dataset\\\\cars_train\\\\Dimensionality Experiments'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "path_dir = os.getcwd()\n",
    "path_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dir = '\\\\'.join((path_dir, \"Images\"))\n",
    "car_names = os.listdir(fold_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#Considering 100 images!\n",
    "np.shape(car_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4131126403808594\n"
     ]
    }
   ],
   "source": [
    "#Without Resizing:\n",
    "start_time = time.time()\n",
    "\n",
    "img_cars = []\n",
    "for file_n in car_names:\n",
    "    file_name = \"\\\\\".join((fold_dir, file_n))\n",
    "    img = np.array(Image.open(file_name).convert('LA'))\n",
    "    #img_grey = tf.image.resize(img, (256,256),preserve_aspect_ratio=False).numpy()\n",
    "    img_cars.append(img[:,:,0])\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.720214605331421\n"
     ]
    }
   ],
   "source": [
    "#For Image Resizing:\n",
    "start_time = time.time()\n",
    "\n",
    "img_cars_resized = []\n",
    "for file_n in car_names:\n",
    "    file_name = \"\\\\\".join((fold_dir, file_n))\n",
    "    img = np.array(Image.open(file_name).convert('LA'))\n",
    "    img_grey = tf.image.resize(img, (256,256),preserve_aspect_ratio=False).numpy()\n",
    "    img_cars_resized.append(img_grey[:,:,0])\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "37.48368549346924\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "fd_filter = []\n",
    "for img in img_cars:\n",
    "    filter_img = gaussian_filter(img, 2)\n",
    "    fd_hog = hog(filter_img, orientations=16, pixels_per_cell=(10, 10), cells_per_block=(1, 1), visualize=False)\n",
    "    fd_filter.append(fd_hog)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4.606943845748901\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "fd_filter_resized = []\n",
    "for img in img_cars_resized:\n",
    "    filter_img_resized = gaussian_filter(img, 2)\n",
    "    fd_hog = hog(filter_img_resized, orientations=16, pixels_per_cell=(10, 10), cells_per_block=(1, 1), visualize=False)\n",
    "    fd_filter_resized.append(fd_hog)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = []\n",
    "for fd in fd_filter:\n",
    "    img_shape.append(np.shape(fd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1221200\n560\n"
     ]
    }
   ],
   "source": [
    "#Number of feature descriptors when the image is not scaled\n",
    "print(np.max(img_shape))\n",
    "print(np.min(img_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape_resized = []\n",
    "for fd in fd_filter_resized:\n",
    "    img_shape_resized.append(np.shape(fd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10000\n10000\n"
     ]
    }
   ],
   "source": [
    "#Minimum and Maximum number of feature descriptors when the image is scaled\n",
    "print(np.max(img_shape_resized))\n",
    "print(np.min(img_shape_resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.36662477, 0.13399333, 0.36662477, ..., 0.25002961, 0.3273042 ,\n",
       "       0.3273042 ])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "fd_filter_resized[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "np.shape(fd_filter_resized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.37117746, 0.37117746, 0.37117746, ..., 0.38612088, 0.38612088,\n",
       "       0.38612088])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "fd_filter_resized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_color = tensorflow.image.resize(img_color, (256,256),preserve_aspect_ratio=False).numpy()\n",
    "# img_r = np.reshape(img_color[:, :, 0], (256,256))\n",
    "# img_g = np.reshape(img_color[:, :, 1], (256,256))\n",
    "# img_b = np.reshape(img_color[:, :, 2], (256,256))\n",
    "\n",
    "# img_grey = tensorflow.image.resize(img_grey, (256,256),preserve_aspect_ratio=False).numpy()\n",
    "# img_grey = np.reshape(img_grey[:, :, 0], newshape=(256,256))\n",
    "\n",
    "# img_hsv = tensorflow.image.resize(img_hsv, (256,256),preserve_aspect_ratio=False).numpy()\n",
    "# img_h = np.reshape(img_hsv[:, :, 0], (256,256))\n",
    "# img_s = np.reshape(img_hsv[:, :, 1], (256,256))\n",
    "# img_v = np.reshape(img_hsv[:, :, 2], (256,256))"
   ]
  }
 ]
}