{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time \n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt \n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'i:\\\\WPI\\\\Fall 2020\\\\Computer Vision - RBE 549\\\\CV Project\\\\Dataset\\\\cars_train\\\\Dimensionality Experiments'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "path_dir = os.getcwd()\n",
    "path_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dir = '\\\\'.join((path_dir, \"Images\"))\n",
    "car_names = os.listdir(fold_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.4142184257507324\n"
     ]
    }
   ],
   "source": [
    "#Without Resizing:\n",
    "start_time = time.time()\n",
    "\n",
    "img_cars = []\n",
    "for file_n in car_names:\n",
    "    file_name = \"\\\\\".join((fold_dir, file_n))\n",
    "    img = np.array(Image.open(file_name).convert('LA'))\n",
    "    #img_grey = tf.image.resize(img, (256,256),preserve_aspect_ratio=False).numpy()\n",
    "    img_cars.append(img[:,:,0])\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.4281504154205322\n"
     ]
    }
   ],
   "source": [
    "#For Image Resizing:\n",
    "start_time = time.time()\n",
    "\n",
    "img_cars_resized = []\n",
    "for file_n in car_names:\n",
    "    file_name = \"\\\\\".join((fold_dir, file_n))\n",
    "    img = np.array(Image.open(file_name).convert('LA'))\n",
    "    img_grey = cv2.resize(img, (256,256)) \n",
    "    img_cars_resized.append(img_grey[:,:,0])\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "np.shape(img_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.284975528717041\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "orb = cv.ORB_create()\n",
    "descriptors_normal = []\n",
    "kp_normal = []\n",
    "for img in img_cars:\n",
    "    kp, imageDesc = orb.detectAndCompute(img, None)\n",
    "    if not imageDesc is None:   \n",
    "        descriptors_normal.append(imageDesc)\n",
    "    if not kp is None:\n",
    "        kp_normal.append(kp)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.4498312473297119\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "orb = cv.ORB_create()\n",
    "descriptors_scaled = []\n",
    "kp_scaled = []\n",
    "for img in img_cars_resized:\n",
    "    kp, imageDesc = orb.detectAndCompute(img, None)\n",
    "    if not imageDesc is None:    \n",
    "        descriptors_scaled.append(imageDesc)\n",
    "    if not kp is None:\n",
    "        kp_scaled.append(kp)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<KeyPoint 0000024F3CE38ED0>,\n",
       " <KeyPoint 0000024F3CE38C00>,\n",
       " <KeyPoint 0000024F3CE385D0>,\n",
       " <KeyPoint 0000024F3CE820F0>,\n",
       " <KeyPoint 0000024F3CE821E0>]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#Key points are useless!\n",
    "kp_scaled[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_original = []\n",
    "normal_shape = []\n",
    "flatten_normal_shape = []\n",
    "for desc in descriptors_normal:\n",
    "    flatten_original.append(np.resize(desc, (-1)))\n",
    "    normal_shape.append(np.shape(desc)[0])\n",
    "    flatten_normal_shape.append(np.shape(np.resize(desc, (-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_scaled = []\n",
    "scaled_shape = []\n",
    "flatten_scaled_shape = []\n",
    "for desc in descriptors_scaled:\n",
    "    flatten_scaled.append(np.resize(desc, (-1)))\n",
    "    scaled_shape.append(np.shape(desc)[0])\n",
    "    flatten_scaled_shape.append(np.shape(np.resize(desc, (-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Maximum Number of Descriptors - Original:  500\nMinimum Number of Descriptors - Original:  193\n\n[193 271 368 376 388 391 393 411 413 439 462 463 477 485 490 492 494 500]\n[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1 81]\n"
     ]
    }
   ],
   "source": [
    "count, values = np.unique(normal_shape, return_counts=True)\n",
    "print(\"Maximum Number of Descriptors - Original: \", np.max(normal_shape))\n",
    "print(\"Minimum Number of Descriptors - Original: \",np.min(normal_shape))\n",
    "print()\n",
    "print(count)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Maximum Number of Descriptors - Scaled:  471\nMinimum Number of Descriptors - Scaled:  381\n\n[381 389 392 393 402 408 409 410 411 412 414 415 417 418 420 422 424 426\n 427 428 429 430 431 432 433 434 435 436 437 439 440 441 442 443 444 445\n 446 447 448 449 450 451 453 454 455 456 457 458 461 463 469 471]\n[1 1 1 1 1 1 1 1 2 1 1 2 3 1 1 3 1 4 2 1 1 1 3 3 2 2 1 2 1 1 3 2 3 1 1 4 3\n 2 1 1 2 5 7 2 1 4 4 2 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "count, values = np.unique(scaled_shape, return_counts=True)\n",
    "print(\"Maximum Number of Descriptors - Scaled: \", np.max(scaled_shape))\n",
    "print(\"Minimum Number of Descriptors - Scaled: \", np.min(scaled_shape))\n",
    "print()\n",
    "print(count)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Maximum Number of Features - Scaled-Flatten:  15071\nMinimum Number of Features - Scaled-Flatten:  12191\n\n[12191 12447 12543 12575 12863 13055 13087 13119 13151 13183 13247 13279\n 13343 13375 13439 13503 13567 13631 13663 13695 13727 13759 13791 13823\n 13855 13887 13919 13951 13983 14047 14079 14111 14143 14175 14207 14239\n 14271 14303 14335 14367 14399 14431 14495 14527 14559 14591 14623 14655\n 14751 14815 15007 15071]\n[1 1 1 1 1 1 1 1 2 1 1 2 3 1 1 3 1 4 2 1 1 1 3 3 2 2 1 2 1 1 3 2 3 1 1 4 3\n 2 1 1 2 5 7 2 1 4 4 2 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "count, values = np.unique(flatten_scaled_shape, return_counts=True)\n",
    "print(\"Maximum Number of Features - Scaled-Flatten: \", np.max(flatten_scaled_shape))\n",
    "print(\"Minimum Number of Features - Scaled-Flatten: \", np.min(flatten_scaled_shape))\n",
    "print()\n",
    "print(count)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Maximum Number of Features - Original-Flatten:  15999\nMinimum Number of Features - Original-Flatten:  6175\n\n[ 6175  8671 11775 12031 12415 12511 12575 13151 13215 14047 14783 14815\n 15263 15519 15679 15743 15807 15999]\n[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1 81]\n"
     ]
    }
   ],
   "source": [
    "count, values = np.unique(flatten_normal_shape, return_counts=True)\n",
    "print(\"Maximum Number of Features - Original-Flatten: \",np.max(flatten_normal_shape))\n",
    "print(\"Minimum Number of Features - Original-Flatten: \",np.min(flatten_normal_shape))\n",
    "print()\n",
    "print(count)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}