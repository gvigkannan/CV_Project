{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Validation for Classifer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_program = time.time()\n",
    "duration = 800  # milliseconds\n",
    "freq = 300 # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trial_1_KMeans_c1500_b32_rs0.sav\n"
     ]
    }
   ],
   "source": [
    "n_cluster = 1500\n",
    "#Trial_1_KMeans_c300_b32_rs0.sav\n",
    "kmeans_name = \"_\".join((\"Trial_1_KMeans\", \"c\"+str(n_cluster), \"b32_rs0.sav\"))\n",
    "with open(kmeans_name, 'rb') as f_name:\n",
    "    kmeans_batch = pickle.load(f_name)\n",
    "print(kmeans_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVC_VoW_MinMax_C1500.sav\n"
     ]
    }
   ],
   "source": [
    "SVC_name = \"_\".join((\"SVC\",\"VoW_MinMax\",\"C\"+str(n_cluster)+\".sav\"))\n",
    "with open(SVC_name, 'rb') as f_name:\n",
    "    svc_model = pickle.load(f_name)\n",
    "print(SVC_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MinMax_C1500.sav\n"
     ]
    }
   ],
   "source": [
    "mm_name = \"_\".join((\"MinMax\",\"C\"+str(n_cluster)+\".sav\"))\n",
    "with open(mm_name, 'rb') as f_name:\n",
    "    mm_scaler = pickle.load(f_name)\n",
    "print(mm_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the prediction accuracy with Validation Data!\n",
    "#Let's import all the feature descriptors!\n",
    "path_dir = os.getcwd()\n",
    "valid_dir = \"\\\\\".join((path_dir, \"ORB_Dataset\", \"val\"))\n",
    "valid_files = os.listdir(valid_dir)\n",
    "valid_car_dir = \"\\\\\".join((valid_dir, valid_files[0]))\n",
    "valid_noise_dir = \"\\\\\".join((valid_dir, valid_files[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.551635980606079\n",
      "2.8164963722229004\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "valid_car_descriptors = []\n",
    "with open(valid_car_dir, 'r') as fil_name:\n",
    "    valid_car_descriptors = json.load(fil_name)\n",
    "print(time.time() - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "valid_noise_descriptors = []\n",
    "with open(valid_noise_dir, 'r') as fil_name:\n",
    "    valid_noise_descriptors = json.load(fil_name)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_labels(pickle_file, model):\n",
    "    start_time = time.time()\n",
    "    #pickle_file = car_descriptors\n",
    "    \n",
    "    img_cluster = []\n",
    "    for img_desc in pickle_file:\n",
    "        cluster_desc = []\n",
    "        if len(img_desc)> 0:\n",
    "            #for desc in img_desc:\n",
    "            cluster_desc = model.predict(img_desc)\n",
    "            img_cluster.append(cluster_desc)\n",
    "    print(time.time() - start_time)\n",
    "    return(img_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14.785331010818481\n",
      "15.077357292175293\n"
     ]
    }
   ],
   "source": [
    "valid_car_clusters = np.array(cluster_labels(pickle_file = valid_car_descriptors, model = kmeans_batch))\n",
    "valid_noise_clusters = np.array(cluster_labels(pickle_file = valid_noise_descriptors, model = kmeans_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_histogram(img_clusters, n_clusters = 500):\n",
    "    start_time = time.time()\n",
    "    hist_arr = []\n",
    "    for img in img_clusters:\n",
    "        hist = np.zeros(n_clusters)\n",
    "        for cluster in img:\n",
    "            hist[cluster] += 1\n",
    "        hist_arr.append(hist)\n",
    "    print(time.time() - start_time)\n",
    "    return(hist_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3626251220703125\n",
      "0.3415672779083252\n"
     ]
    }
   ],
   "source": [
    "car_hist = cluster_histogram(img_clusters = valid_car_clusters, n_clusters = n_cluster)\n",
    "noise_hist = cluster_histogram(img_clusters = valid_noise_clusters, n_clusters = n_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = pd.DataFrame(car_hist)\n",
    "car_df = pd.DataFrame(mm_scaler.transform(car_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_df = pd.DataFrame(noise_hist)\n",
    "noise_df = pd.DataFrame(mm_scaler.transform(noise_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['y'] = 1\n",
    "noise_df['y'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   0     1     2         3     4         5         6      7     8     \\\n0   0.0   0.0   0.0  0.166667   0.0  0.000000  0.000000  0.000   0.0   \n1   0.0   0.0   0.0  0.000000   0.6  0.142857  0.000000  0.000   0.0   \n2   0.0   0.0   0.0  0.000000   0.0  0.000000  0.111111  0.000   0.0   \n3   0.0   0.0   0.0  0.000000   0.0  0.000000  0.111111  0.125   0.0   \n4   0.0   0.0   0.0  0.000000   0.2  0.000000  0.000000  0.000   0.0   \n\n       9     ...   1490  1491      1492  1493  1494      1495  1496      1497  \\\n0  0.000000  ...  0.125   0.0  0.000000   0.0   0.4  0.000000   0.0  0.142857   \n1  0.142857  ...  0.125   0.0  0.000000   0.0   0.2  0.000000   0.0  0.000000   \n2  0.000000  ...  0.125   0.0  0.000000   0.0   0.2  0.000000   0.0  0.000000   \n3  0.000000  ...  0.000   0.0  0.000000   0.0   0.2  0.166667   0.2  0.285714   \n4  0.000000  ...  0.250   0.0  0.142857   0.2   0.0  0.000000   0.0  0.142857   \n\n    1498      1499  \n0  0.125  0.166667  \n1  0.000  0.000000  \n2  0.000  0.166667  \n3  0.000  0.000000  \n4  0.000  0.000000  \n\n[5 rows x 1500 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1490</th>\n      <th>1491</th>\n      <th>1492</th>\n      <th>1493</th>\n      <th>1494</th>\n      <th>1495</th>\n      <th>1496</th>\n      <th>1497</th>\n      <th>1498</th>\n      <th>1499</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.125</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.4</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.142857</td>\n      <td>0.125</td>\n      <td>0.166667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.6</td>\n      <td>0.142857</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.142857</td>\n      <td>...</td>\n      <td>0.125</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.2</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.125</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.2</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n      <td>0.166667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>0.125</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.2</td>\n      <td>0.166667</td>\n      <td>0.2</td>\n      <td>0.285714</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.250</td>\n      <td>0.0</td>\n      <td>0.142857</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.142857</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 1500 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0    1\n1    1\n2    1\n3    1\n4    1\nName: y, dtype: int64"
     },
     "metadata": {}
    }
   ],
   "source": [
    "df = pd.concat([car_df, noise_df])\n",
    "X = df.drop(columns = ['y'])\n",
    "y = df['y']\n",
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, Y_valid = shuffle(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_predict = svc_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Clusters:  1500\nF1_score for Validation with clusters: 1500 = \t0.8141\nAccuracy for Validation with clusters: 1500 = \t0.8222\nPrecision for Validation with clusters: 1500 = \t0.8372\nRecall for Validation with clusters: 1500 = \t0.7922\nAUC Score for Validation with clusters: 1500 = \t0.8217\n"
     ]
    }
   ],
   "source": [
    "print(\"For Clusters: \", n_cluster)\n",
    "print(\"F1_score for Validation with clusters: {} = \\t{:.4f}\".format(n_cluster, f1_score(y_true = Y_valid, y_pred = Y_val_predict)) )\n",
    "print(\"Accuracy for Validation with clusters: {} = \\t{:.4f}\".format(n_cluster, accuracy_score(y_true = Y_valid, y_pred = Y_val_predict)) )\n",
    "print(\"Precision for Validation with clusters: {} = \\t{:.4f}\".format(n_cluster, precision_score(y_true = Y_valid, y_pred = Y_val_predict)) )\n",
    "print(\"Recall for Validation with clusters: {} = \\t{:.4f}\".format(n_cluster, recall_score(y_true = Y_valid, y_pred = Y_val_predict)) )\n",
    "print(\"AUC Score for Validation with clusters: {} = \\t{:.4f}\".format(n_cluster, roc_auc_score(y_true = Y_valid, y_score = Y_val_predict)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}